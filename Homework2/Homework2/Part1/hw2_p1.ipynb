{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HakureiPOI/computer-vision-2025/blob/main/Homework2/Homework2/Part1/hw2_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 220110720 HakureiPOI"
      ],
      "metadata": {
        "id": "EBSvHE9_Slhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HakureiPOI/computer-vision-2025.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjQQYeuISofg",
        "outputId": "f3e05d98-bbf3-4372-fd35-1dcb1801e339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'computer-vision-2025'...\n",
            "remote: Enumerating objects: 567, done.\u001b[K\n",
            "remote: Counting objects: 100% (567/567), done.\u001b[K\n",
            "remote: Compressing objects: 100% (543/543), done.\u001b[K\n",
            "remote: Total 567 (delta 24), reused 493 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (567/567), 11.89 MiB | 22.80 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/computer-vision-2025/Homework2/Homework2/Part1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1juu0eFSpZJ",
        "outputId": "da878ba6-dcc6-4c62-f716-e80be3b36b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/computer-vision-2025/Homework2/Homework2/Part1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Wv7C63k0Sp2F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk03Q5Q_Sb1G"
      },
      "source": [
        "# Homework 2 Part1\n",
        "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n",
        "\n",
        "This assignment covers linear filters, convolution and correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSa1KOGcSb1G"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Convolutions"
      ],
      "metadata": {
        "id": "sa-CyaAqmAqs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1v3Me69Sb1H"
      },
      "source": [
        "### 1.1 Commutative Property (5 points)\n",
        "\n",
        "Recall that the convolution of an image $f:\\mathbb{R}^2\\rightarrow \\mathbb{R}$ and a kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$ is defined as follows:\n",
        "$$(f*h)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty f[i,j]\\cdot h[m-i,n-j]$$\n",
        "\n",
        "Or equivalently,\n",
        "\\begin{align}\n",
        "(f*h)[m,n] &= \\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty h[i,j]\\cdot f[m-i,n-j]\\\\\n",
        "&= (h*f)[m,n]\n",
        "\\end{align}\n",
        "\n",
        "Show that this is true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F09V4mlUSb1H"
      },
      "source": [
        "**Your Answer:**\n",
        "\n",
        "根据定义：\n",
        "$$\n",
        "(f * h)[m, n] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} f[i, j] \\cdot h[m - i, n - j]\n",
        "$$\n",
        "\n",
        "我们希望将其变形为：\n",
        "$$\n",
        "(h * f)[m, n] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} h[i, j] \\cdot f[m - i, n - j]\n",
        "$$\n",
        "\n",
        "\n",
        "我们从 $ (f * h)[m, n] $ 出发，进行变量替换\n",
        "\n",
        "令：\n",
        "$$\n",
        "u = m - i \\quad \\Rightarrow \\quad i = m - u \\\\\n",
        "v = n - j \\quad \\Rightarrow \\quad j = n - v\n",
        "$$\n",
        "\n",
        "由于 $ i, j $ 遍历所有整数，$ u, v $ 也将遍历所有整数。\n",
        "\n",
        "将其代入卷积式中：\n",
        "$$\n",
        "(f * h)[m, n] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} f[i, j] \\cdot h[m - i, n - j]\n",
        "$$\n",
        "\n",
        "变为：\n",
        "$$\n",
        "= \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty} f[m - u, n - v] \\cdot h[u, v]\n",
        "$$\n",
        "\n",
        "根据乘法交换律，我们可以调换顺序：\n",
        "$$\n",
        "= \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty} h[u, v] \\cdot f[m - u, n - v]\n",
        "= (h * f)[m, n]\n",
        "$$\n",
        "\n",
        "\n",
        "我们已经证明：\n",
        "$$\n",
        "(f * h)[m, n] = (h * f)[m, n]\n",
        "$$\n",
        "因此，二维离散卷积是**交换的**，即：\n",
        "$$\n",
        "f * h = h * f\n",
        "$$\n",
        "\n",
        "证毕"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUCn0HD_Sb1H"
      },
      "source": [
        "### 1.2 Shift Invariance (5 points)\n",
        "Let $f$ be a function $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Also consider functions $f'[m,n] = f[m-m_0, n-n_0]$ and $g'[m,n] = g[m-m_0, n-n_0]$.  \n",
        "\n",
        "Show that $S$ defined by any kernel $h$ is a shift invariant system by showing that $g' = (f'*h)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7GNQUZnSb1H"
      },
      "source": [
        "**Your Answer:**\n",
        "\n",
        "我们需要证明：\n",
        "$$\n",
        "g' = f' * h\n",
        "$$\n",
        "也就是说：\n",
        "$$\n",
        "g[m - m_0, n - n_0] = (f' * h)[m, n]\n",
        "$$\n",
        "\n",
        "\n",
        "根据卷积定义：\n",
        "$$\n",
        "(f' * h)[m, n] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} f'[i, j] \\cdot h[m - i, n - j]\n",
        "$$\n",
        "\n",
        "将 $ f'[i, j] = f[i - m_0, j - n_0] $ 代入：\n",
        "$$\n",
        "= \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} f[i - m_0, j - n_0] \\cdot h[m - i, n - j]\n",
        "$$\n",
        "\n",
        "做变量替换：令  \n",
        "$$\n",
        "u = i - m_0 \\Rightarrow i = u + m_0 \\\\\n",
        "v = j - n_0 \\Rightarrow j = v + n_0\n",
        "$$\n",
        "\n",
        "由于 $ i, j $ 遍历所有整数，$ u, v $ 也遍历所有整数：\n",
        "\n",
        "代入后得到：\n",
        "$$\n",
        "= \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty} f[u, v] \\cdot h[m - (u + m_0), n - (v + n_0)]\n",
        "$$\n",
        "$$\n",
        "= \\sum_{u,v} f[u, v] \\cdot h[(m - m_0) - u, (n - n_0) - v]\n",
        "$$\n",
        "\n",
        "即：\n",
        "$$\n",
        "(f * h)[m - m_0, n - n_0] = g[m - m_0, n - n_0] = g'[m, n]\n",
        "$$\n",
        "\n",
        "我们已经证明：\n",
        "$$\n",
        "(f' * h)[m, n] = g'[m, n]\n",
        "$$\n",
        "即：\n",
        "$$\n",
        "g' = f' * h\n",
        "$$\n",
        "\n",
        "因此，系统 $ S: f \\mapsto f * h $ 是 **平移不变的**。\n",
        "\n",
        "证毕"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbAb_APGSb1H"
      },
      "source": [
        "\n",
        "### 1.3 Linearity (10 points)\n",
        "\n",
        "Recall that a system S is considered a linear system if and only if it satisfies the superposition property. In mathematical terms, a (function) S is a linear invariant system iff it satisfies:\n",
        "\n",
        "$$\n",
        "S\\{\\alpha f_1[n,m] + \\beta f_2[n,m]\\} = \\alpha S\\{f_1[n,m]\\} + \\beta S\\{f_2[n,m]\\}\n",
        "$$\n",
        "\n",
        "Let $f_1$ and $f_2$ be functions $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$.  \n",
        "\n",
        "Prove that $S$ defined by any kernel $h$ is linear by showing that the superposition property holds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJLDr0FbSb1H"
      },
      "source": [
        "**Your Answer:**\n",
        "\n",
        "我们要证明：\n",
        "\n",
        "$$\n",
        "S\\{\\alpha f_1 + \\beta f_2\\} = (\\alpha f_1 + \\beta f_2) * h = \\alpha(f_1 * h) + \\beta(f_2 * h)\n",
        "$$\n",
        "\n",
        "\n",
        "从卷积定义出发：\n",
        "$$\n",
        "(\\alpha f_1 + \\beta f_2) * h [m,n]\n",
        "= \\sum_{i,j} (\\alpha f_1[i,j] + \\beta f_2[i,j]) \\cdot h[m - i, n - j]\n",
        "$$\n",
        "\n",
        "使用分配律展开：\n",
        "$$\n",
        "= \\alpha \\sum_{i,j} f_1[i,j] \\cdot h[m - i, n - j] + \\beta \\sum_{i,j} f_2[i,j] \\cdot h[m - i, n - j]\n",
        "= \\alpha (f_1 * h)[m,n] + \\beta (f_2 * h)[m,n]\n",
        "$$\n",
        "\n",
        "因此，\n",
        "$$\n",
        "S\\{\\alpha f_1 + \\beta f_2\\} = \\alpha S(f_1) + \\beta S(f_2)\n",
        "\\Rightarrow S \\text{ 是线性系统}\n",
        "$$\n",
        "\n",
        "证毕"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0InSc5OgSb1I"
      },
      "source": [
        "### 1.4 Implementation (30 points)\n",
        "\n",
        "In this section, you will implement two versions of convolution:\n",
        "- `conv_nested`\n",
        "- `conv_fast`\n",
        "\n",
        "First, run the code cell below to load the image to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "AFyGx3vnSb1I",
        "outputId": "49f82f2f-9e12-4303-e79b-963dc72149f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'io' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a219d97b326>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open image as grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Show image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
          ]
        }
      ],
      "source": [
        "# Open image as grayscale\n",
        "img = io.imread('dog.jpg', as_gray=True)\n",
        "\n",
        "# Show image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(\"Isn't he cute?\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEHf0ROASb1I"
      },
      "source": [
        "Now, implement the function **`conv_nested`** in **`filters.py`**. This is a naive implementation of convolution which uses 4 nested for-loops. It takes an image $f$ and a kernel $h$ as inputs and outputs the convolved image $(f*h)$ that has the same shape as the input image. This implementation should take a few seconds to run.\n",
        "\n",
        "*- Hint: It may be easier to implement $(h*f)$*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTJpgJ6DSb1I"
      },
      "source": [
        "We'll first test your `conv_nested` function on a simple input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTjJzWaASb1I"
      },
      "outputs": [],
      "source": [
        "from filters import conv_nested\n",
        "\n",
        "# Simple convolution kernel.\n",
        "kernel = np.array(\n",
        "[\n",
        "    [1,0,1],\n",
        "    [0,0,0],\n",
        "    [1,0,0]\n",
        "])\n",
        "\n",
        "# Create a test image: a white square in the middle\n",
        "test_img = np.zeros((9, 9))\n",
        "test_img[3:6, 3:6] = 1\n",
        "\n",
        "# Run your conv_nested function on the test image\n",
        "test_output = conv_nested(test_img, kernel)\n",
        "\n",
        "# Build the expected output\n",
        "expected_output = np.zeros((9, 9))\n",
        "expected_output[2:7, 2:7] = 1\n",
        "expected_output[5:, 5:] = 0\n",
        "expected_output[4, 2:5] = 2\n",
        "expected_output[2:5, 4] = 2\n",
        "expected_output[4, 4] = 3\n",
        "\n",
        "# Plot the test image\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_img)\n",
        "plt.title('Test image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot your convolved image\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(test_output)\n",
        "plt.title('Convolution')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the exepected output\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(expected_output)\n",
        "plt.title('Exepected output')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Test if the output matches expected output\n",
        "assert np.max(test_output - expected_output) < 1e-10, \"Your solution is not correct.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4V-ZXZISb1I"
      },
      "source": [
        "Now let's test your `conv_nested` function on a real image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-yjx899Sb1I"
      },
      "outputs": [],
      "source": [
        "from filters import conv_nested\n",
        "\n",
        "# Simple convolution kernel.\n",
        "# Feel free to change the kernel to see different outputs.\n",
        "kernel = np.array(\n",
        "[\n",
        "    [1,0,-1],\n",
        "    [2,0,-2],\n",
        "    [1,0,-1]\n",
        "])\n",
        "\n",
        "out = conv_nested(img, kernel)\n",
        "\n",
        "# Plot original image\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot your convolved image\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(out)\n",
        "plt.title('Convolution')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot what you should get\n",
        "solution_img = io.imread('convolved_dog.png', as_gray=True)\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(solution_img)\n",
        "plt.title('What you should get')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovvYiHZoSb1I"
      },
      "source": [
        "Let us implement a more efficient version of convolution using array operations in numpy. As shown in the lecture, a convolution can be considered as a sliding window that computes sum of the pixel values weighted by the flipped kernel. The faster version will i) zero-pad an image, ii) flip the kernel horizontally and vertically, and iii) compute weighted sum of the neighborhood at each pixel.\n",
        "\n",
        "First, implement the function **`zero_pad`** in **`filters.py`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aDhuBxDSb1I"
      },
      "outputs": [],
      "source": [
        "from filters import zero_pad\n",
        "\n",
        "pad_width = 20 # width of the padding on the left and right\n",
        "pad_height = 40 # height of the padding on the top and bottom\n",
        "\n",
        "padded_img = zero_pad(img, pad_height, pad_width)\n",
        "\n",
        "# Plot your padded dog\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(padded_img)\n",
        "plt.title('Padded dog')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot what you should get\n",
        "solution_img = io.imread('padded_dog.jpg', as_gray=True)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(solution_img)\n",
        "plt.title('What you should get')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItpA9-HmSb1I"
      },
      "source": [
        "Next, complete the function **`conv_fast`** in **`filters.py`** using `zero_pad`. Run the code below to compare the outputs by the two implementations. `conv_fast` should run noticeably faster than `conv_nested`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nAoyS3dSb1I"
      },
      "outputs": [],
      "source": [
        "from filters import conv_fast\n",
        "\n",
        "t0 = time()\n",
        "out_fast = conv_fast(img, kernel)\n",
        "t1 = time()\n",
        "out_nested = conv_nested(img, kernel)\n",
        "t2 = time()\n",
        "\n",
        "# Compare the running time of the two implementations\n",
        "print(\"conv_nested: took %f seconds.\" % (t2 - t1))\n",
        "print(\"conv_fast: took %f seconds.\" % (t1 - t0))\n",
        "\n",
        "# Plot conv_nested output\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(out_nested)\n",
        "plt.title('conv_nested')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot conv_fast output\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(out_fast)\n",
        "plt.title('conv_fast')\n",
        "plt.axis('off')\n",
        "\n",
        "# Make sure that the two outputs are the same\n",
        "if not (np.max(out_fast - out_nested) < 1e-10):\n",
        "    print(\"Different outputs! Check your implementation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my6OQmxmSb1I"
      },
      "source": [
        "---\n",
        "## Part 2: Cross-correlation\n",
        "\n",
        "Cross-correlation of an image $f$ with a template $g$ is defined as follows:\n",
        "$$(g ** f)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty g[i,j]\\cdot f[m + i,n + j]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j6zINQj3lwrO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAfn8sIUSb1I"
      },
      "source": [
        "### 2.1 Template Matching with Cross-correlation (20 points)\n",
        "Suppose that you are a clerk at a grocery store. One of your responsibilites is to check the shelves periodically and stock them up whenever there are sold-out items. You got tired of this laborious task and decided to build a computer vision system that keeps track of the items on the shelf.\n",
        "\n",
        "Luckily, you have learned in CS131 that cross-correlation can be used for template matching: a template $g$ is multiplied with regions of a larger image $f$ to measure how similar each region is to the template.\n",
        "\n",
        "The template of a product (`template.jpg`) and the image of shelf (`shelf.jpg`) is provided. We will use cross-correlation to find the product in the shelf.\n",
        "\n",
        "Implement **`cross_correlation`** function in **`filters.py`** and run the code below.\n",
        "\n",
        "*- Hint: you may use the `conv_fast` function you implemented in the previous question.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvbII3RoSb1I"
      },
      "outputs": [],
      "source": [
        "from filters import cross_correlation\n",
        "\n",
        "# Load template and image in grayscale\n",
        "img = io.imread('shelf.jpg')\n",
        "img_gray = io.imread('shelf.jpg', as_gray=True)\n",
        "temp = io.imread('template.jpg')\n",
        "temp_gray = io.imread('template.jpg', as_gray=True)\n",
        "\n",
        "# Perform cross-correlation between the image and the template\n",
        "out = cross_correlation(img_gray, temp_gray)\n",
        "\n",
        "# Find the location with maximum similarity\n",
        "y,x = (np.unravel_index(out.argmax(), out.shape))\n",
        "\n",
        "# Display product template\n",
        "plt.figure(figsize=(25,20))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(temp)\n",
        "plt.title('Template')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display cross-correlation output\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(out)\n",
        "plt.title('Cross-correlation (white means more correlated)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display image\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(img)\n",
        "plt.title('Result (blue marker on the detected location)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Draw marker at detected location\n",
        "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWeZyTR1Sb1J"
      },
      "source": [
        "#### Interpretation\n",
        "How does the output of cross-correlation filter look? Explain what problems there might be with using a raw template as a filter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruKJsUsGSb1J"
      },
      "source": [
        "**Your Answer:** *Write your solution in this markdown cell.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ0grg4oSb1J"
      },
      "source": [
        "---\n",
        "### 2.2 Zero-mean cross-correlation (10 points)\n",
        "A solution to this problem is to subtract the mean value of the template so that it has zero mean.\n",
        "\n",
        "Implement **`zero_mean_cross_correlation`** function in **`filters.py`** and run the code below.\n",
        "\n",
        "**If your implementation is correct, you should see the blue cross centered over the correct cereal box.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an9KA33RSb1J"
      },
      "outputs": [],
      "source": [
        "from filters import zero_mean_cross_correlation\n",
        "\n",
        "# Perform cross-correlation between the image and the template\n",
        "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
        "\n",
        "# Find the location with maximum similarity\n",
        "y,x = np.unravel_index(out.argmax(), out.shape)\n",
        "\n",
        "# Display product template\n",
        "plt.figure(figsize=(30,20))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(temp)\n",
        "plt.title('Template')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display cross-correlation output\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(out)\n",
        "plt.title('Cross-correlation (white means more correlated)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display image\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(img)\n",
        "plt.title('Result (blue marker on the detected location)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Draw marker at detected location\n",
        "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTRUXXYSb1J"
      },
      "source": [
        "You can also determine whether the product is present with appropriate scaling and thresholding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-834LtASb1J"
      },
      "outputs": [],
      "source": [
        "def check_product_on_shelf(shelf, product):\n",
        "    out = zero_mean_cross_correlation(shelf, product)\n",
        "\n",
        "    # Scale output by the size of the template\n",
        "    out = out / float(product.shape[0]*product.shape[1])\n",
        "\n",
        "    # Threshold output (this is arbitrary, you would need to tune the threshold for a real application)\n",
        "    out = out > 0.025\n",
        "\n",
        "    if np.sum(out) > 0:\n",
        "        print('The product is on the shelf')\n",
        "    else:\n",
        "        print('The product is not on the shelf')\n",
        "\n",
        "# Load image of the shelf without the product\n",
        "img2 = io.imread('shelf_soldout.jpg')\n",
        "img2_gray = io.imread('shelf_soldout.jpg', as_gray=True)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "check_product_on_shelf(img_gray, temp_gray)\n",
        "\n",
        "plt.imshow(img2)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "check_product_on_shelf(img2_gray, temp_gray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j2LtcmDSb1J"
      },
      "source": [
        "---\n",
        "### 2.3 Normalized Cross-correlation(20 points)\n",
        "One day the light near the shelf goes out and the product tracker starts to malfunction. The `zero_mean_cross_correlation` is not robust to change in lighting condition. The code below demonstrates this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqFh328VSb1J"
      },
      "outputs": [],
      "source": [
        "from filters import normalized_cross_correlation\n",
        "\n",
        "# Load image\n",
        "img = io.imread('shelf_dark.jpg')\n",
        "img_gray = io.imread('shelf_dark.jpg', as_gray=True)\n",
        "\n",
        "# Perform cross-correlation between the image and the template\n",
        "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
        "\n",
        "# Find the location with maximum similarity\n",
        "y, x = np.unravel_index(out.argmax(), out.shape)\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.title('Result (red marker on the detected location)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Draw marker at detcted location\n",
        "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh8Qx2jVSb1J"
      },
      "source": [
        "A solution is to normalize the pixels of the image and template at every step before comparing them. This is called **normalized cross-correlation**.\n",
        "\n",
        "The mathematical definition for normalized cross-correlation of $f$ and template $g$ is:\n",
        "$$(g \\star f)[m,n]=\\sum_{i,j} \\frac{g[i, j]-\\overline{g}}{\\sigma_g} \\cdot \\frac{f[m + i, n + j]-\\overline{f_{m,n}}}{\\sigma_{f_{m,n}}}$$\n",
        "\n",
        "where:\n",
        "- $f_{m,n}$ is the patch image at position $(m,n)$\n",
        "- $\\overline{f_{m,n}}$ is the mean of the patch image $f_{m,n}$\n",
        "- $\\sigma_{f_{m,n}}$ is the standard deviation of the patch image $f_{m,n}$\n",
        "- $\\overline{g}$ is the mean of the template $g$\n",
        "- $\\sigma_g$ is the standard deviation of the template $g$\n",
        "\n",
        "Implement **`normalized_cross_correlation`** function in **`filters.py`** and run the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahT5PCXOSb1J"
      },
      "outputs": [],
      "source": [
        "from filters import normalized_cross_correlation\n",
        "\n",
        "# Perform normalized cross-correlation between the image and the template\n",
        "out = normalized_cross_correlation(img_gray, temp_gray)\n",
        "\n",
        "# Find the location with maximum similarity\n",
        "y, x = np.unravel_index(out.argmax(), out.shape)\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.title('Result (red marker on the detected location)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Draw marker at detcted location\n",
        "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}